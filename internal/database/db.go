// Package database provides database connection and management.
package database

import (
	"context"
	"fmt"
	"sync"
	"time"

	"github.com/glebarez/sqlite"
	"gorm.io/gorm"
	"gorm.io/gorm/logger"

	"v/internal/database/repository"
)

// Config holds database configuration.
type Config struct {
	Driver          string
	DSN             string
	MaxOpenConns    int
	MaxIdleConns    int
	ConnMaxLifetime time.Duration

	// Health check and retry settings
	HealthCheckInterval time.Duration
	MaxRetries          int
	RetryInterval       time.Duration
	SlowQueryThreshold  time.Duration
}

// DefaultConfig returns default database configuration.
func DefaultConfig() Config {
	return Config{
		Driver:              "sqlite",
		MaxOpenConns:        25,
		MaxIdleConns:        5,
		ConnMaxLifetime:     5 * time.Minute,
		HealthCheckInterval: 30 * time.Second,
		MaxRetries:          3,
		RetryInterval:       time.Second,
		SlowQueryThreshold:  200 * time.Millisecond,
	}
}

// Database wraps the GORM database connection.
type Database struct {
	db     *gorm.DB
	config *Config
	mu     sync.RWMutex

	// Health check
	healthy   bool
	lastCheck time.Time
	stopCh    chan struct{}
}

// New creates a new database connection.
func New(cfg *Config) (*Database, error) {
	var dialector gorm.Dialector

	switch cfg.Driver {
	case "sqlite", "sqlite3", "":
		dialector = sqlite.Open(cfg.DSN)
	default:
		return nil, fmt.Errorf("unsupported database driver: %s", cfg.Driver)
	}

	// Set default values
	if cfg.HealthCheckInterval <= 0 {
		cfg.HealthCheckInterval = 30 * time.Second
	}
	if cfg.MaxRetries <= 0 {
		cfg.MaxRetries = 3
	}
	if cfg.RetryInterval <= 0 {
		cfg.RetryInterval = time.Second
	}
	if cfg.SlowQueryThreshold <= 0 {
		cfg.SlowQueryThreshold = 200 * time.Millisecond
	}

	// Create slow query logger
	slowLogger := newSlowQueryLogger(cfg.SlowQueryThreshold)

	gormConfig := &gorm.Config{
		Logger: slowLogger,
	}

	db, err := gorm.Open(dialector, gormConfig)
	if err != nil {
		return nil, fmt.Errorf("failed to connect to database: %w", err)
	}

	// Get underlying SQL DB
	sqlDB, err := db.DB()
	if err != nil {
		return nil, fmt.Errorf("failed to get underlying DB: %w", err)
	}

	// Configure connection pool
	if cfg.MaxOpenConns > 0 {
		sqlDB.SetMaxOpenConns(cfg.MaxOpenConns)
	}
	if cfg.MaxIdleConns > 0 {
		sqlDB.SetMaxIdleConns(cfg.MaxIdleConns)
	}
	if cfg.ConnMaxLifetime > 0 {
		sqlDB.SetConnMaxLifetime(cfg.ConnMaxLifetime)
	}

	database := &Database{
		db:      db,
		config:  cfg,
		healthy: true,
		stopCh:  make(chan struct{}),
	}

	// Start health check goroutine
	go database.healthCheckLoop()

	return database, nil
}

// DB returns the underlying GORM database.
func (d *Database) DB() *gorm.DB {
	d.mu.RLock()
	defer d.mu.RUnlock()
	return d.db
}

// Close closes the database connection.
func (d *Database) Close() error {
	// Stop health check
	close(d.stopCh)

	sqlDB, err := d.db.DB()
	if err != nil {
		return err
	}
	return sqlDB.Close()
}

// AutoMigrate runs database migrations.
func (d *Database) AutoMigrate() error {
	return d.db.AutoMigrate(
		&repository.User{},
		&repository.Proxy{},
		&repository.Traffic{},
		&repository.LoginHistory{},
		&repository.Role{},
		&repository.AuditLog{},
		&repository.Setting{},
	)
}

// Ping checks the database connection.
func (d *Database) Ping() error {
	sqlDB, err := d.db.DB()
	if err != nil {
		return err
	}
	return sqlDB.Ping()
}

// IsHealthy returns the current health status.
func (d *Database) IsHealthy() bool {
	d.mu.RLock()
	defer d.mu.RUnlock()
	return d.healthy
}

// LastHealthCheck returns the time of the last health check.
func (d *Database) LastHealthCheck() time.Time {
	d.mu.RLock()
	defer d.mu.RUnlock()
	return d.lastCheck
}

// healthCheckLoop periodically checks database health.
func (d *Database) healthCheckLoop() {
	ticker := time.NewTicker(d.config.HealthCheckInterval)
	defer ticker.Stop()

	for {
		select {
		case <-ticker.C:
			d.checkHealth()
		case <-d.stopCh:
			return
		}
	}
}

// checkHealth performs a health check and attempts reconnection if needed.
func (d *Database) checkHealth() {
	ctx, cancel := context.WithTimeout(context.Background(), 5*time.Second)
	defer cancel()

	err := d.PingContext(ctx)

	d.mu.Lock()
	d.lastCheck = time.Now()
	if err != nil {
		d.healthy = false
		d.mu.Unlock()

		// Attempt reconnection
		d.reconnect()
	} else {
		d.healthy = true
		d.mu.Unlock()
	}
}

// PingContext checks the database connection with context.
func (d *Database) PingContext(ctx context.Context) error {
	sqlDB, err := d.db.DB()
	if err != nil {
		return err
	}
	return sqlDB.PingContext(ctx)
}

// reconnect attempts to reconnect to the database with exponential backoff.
func (d *Database) reconnect() {
	for i := 0; i < d.config.MaxRetries; i++ {
		// Exponential backoff
		backoff := d.config.RetryInterval * time.Duration(1<<uint(i))
		time.Sleep(backoff)

		ctx, cancel := context.WithTimeout(context.Background(), 5*time.Second)
		err := d.PingContext(ctx)
		cancel()

		if err == nil {
			d.mu.Lock()
			d.healthy = true
			d.mu.Unlock()
			return
		}
	}
}

// WithRetry executes a database operation with retry logic.
func (d *Database) WithRetry(ctx context.Context, fn func(*gorm.DB) error) error {
	var lastErr error

	for i := 0; i <= d.config.MaxRetries; i++ {
		if i > 0 {
			// Exponential backoff
			backoff := d.config.RetryInterval * time.Duration(1<<uint(i-1))
			select {
			case <-ctx.Done():
				return ctx.Err()
			case <-time.After(backoff):
			}
		}

		err := fn(d.db.WithContext(ctx))
		if err == nil {
			return nil
		}

		lastErr = err

		// Check if error is retryable
		if !isRetryableError(err) {
			return err
		}
	}

	return fmt.Errorf("operation failed after %d retries: %w", d.config.MaxRetries, lastErr)
}

// isRetryableError checks if an error is retryable.
func isRetryableError(err error) bool {
	if err == nil {
		return false
	}

	errStr := err.Error()
	retryableErrors := []string{
		"database is locked",
		"connection refused",
		"connection reset",
		"broken pipe",
		"timeout",
		"deadlock",
	}

	for _, retryable := range retryableErrors {
		if contains(errStr, retryable) {
			return true
		}
	}

	return false
}

func contains(s, substr string) bool {
	return len(s) >= len(substr) && (s == substr || len(s) > 0 && containsImpl(s, substr))
}

func containsImpl(s, substr string) bool {
	for i := 0; i <= len(s)-len(substr); i++ {
		if s[i:i+len(substr)] == substr {
			return true
		}
	}
	return false
}

// HealthStatus represents database health status.
type HealthStatus struct {
	Healthy   bool      `json:"healthy"`
	LastCheck time.Time `json:"last_check"`
	Latency   string    `json:"latency,omitempty"`
	Error     string    `json:"error,omitempty"`
}

// Health returns detailed health status.
func (d *Database) Health(ctx context.Context) HealthStatus {
	start := time.Now()
	err := d.PingContext(ctx)
	latency := time.Since(start)

	status := HealthStatus{
		Healthy:   err == nil,
		LastCheck: time.Now(),
		Latency:   latency.String(),
	}

	if err != nil {
		status.Error = err.Error()
	}

	return status
}


// slowQueryLogger implements GORM logger interface for slow query logging.
type slowQueryLogger struct {
	threshold time.Duration
	logger.Interface
}

// newSlowQueryLogger creates a new slow query logger.
func newSlowQueryLogger(threshold time.Duration) *slowQueryLogger {
	return &slowQueryLogger{
		threshold: threshold,
		Interface: logger.Default.LogMode(logger.Silent),
	}
}

// LogMode implements logger.Interface.
func (l *slowQueryLogger) LogMode(level logger.LogLevel) logger.Interface {
	return l
}

// Info implements logger.Interface.
func (l *slowQueryLogger) Info(ctx context.Context, msg string, data ...interface{}) {
	// Silent
}

// Warn implements logger.Interface.
func (l *slowQueryLogger) Warn(ctx context.Context, msg string, data ...interface{}) {
	// Silent
}

// Error implements logger.Interface.
func (l *slowQueryLogger) Error(ctx context.Context, msg string, data ...interface{}) {
	// Log errors
	fmt.Printf("[DB ERROR] %s %v\n", msg, data)
}

// SlowQueryLog represents a slow query log entry.
type SlowQueryLog struct {
	SQL      string        `json:"sql"`
	Duration time.Duration `json:"duration"`
	Rows     int64         `json:"rows"`
	Time     time.Time     `json:"time"`
}

// slowQueryLogs stores recent slow queries for monitoring.
var (
	slowQueryLogs   []SlowQueryLog
	slowQueryLogsMu sync.RWMutex
	maxSlowQueries  = 100
)

// Trace implements logger.Interface for query tracing.
func (l *slowQueryLogger) Trace(ctx context.Context, begin time.Time, fc func() (sql string, rowsAffected int64), err error) {
	elapsed := time.Since(begin)
	sql, rows := fc()

	// Log slow queries
	if elapsed > l.threshold {
		log := SlowQueryLog{
			SQL:      sql,
			Duration: elapsed,
			Rows:     rows,
			Time:     begin,
		}

		// Store in memory for monitoring
		slowQueryLogsMu.Lock()
		slowQueryLogs = append(slowQueryLogs, log)
		if len(slowQueryLogs) > maxSlowQueries {
			slowQueryLogs = slowQueryLogs[1:]
		}
		slowQueryLogsMu.Unlock()

		// Print to stdout (can be captured by logging system)
		fmt.Printf("[SLOW QUERY] duration=%s rows=%d sql=%s\n", elapsed, rows, sql)
	}

	// Log errors
	if err != nil && err != gorm.ErrRecordNotFound {
		fmt.Printf("[DB ERROR] duration=%s err=%v sql=%s\n", elapsed, err, sql)
	}
}

// GetSlowQueries returns recent slow queries.
func GetSlowQueries() []SlowQueryLog {
	slowQueryLogsMu.RLock()
	defer slowQueryLogsMu.RUnlock()

	result := make([]SlowQueryLog, len(slowQueryLogs))
	copy(result, slowQueryLogs)
	return result
}

// ClearSlowQueries clears the slow query log.
func ClearSlowQueries() {
	slowQueryLogsMu.Lock()
	defer slowQueryLogsMu.Unlock()
	slowQueryLogs = nil
}

// SetSlowQueryThreshold updates the slow query threshold.
func (d *Database) SetSlowQueryThreshold(threshold time.Duration) {
	if l, ok := d.db.Logger.(*slowQueryLogger); ok {
		l.threshold = threshold
	}
}

// GetSlowQueryThreshold returns the current slow query threshold.
func (d *Database) GetSlowQueryThreshold() time.Duration {
	if l, ok := d.db.Logger.(*slowQueryLogger); ok {
		return l.threshold
	}
	return 0
}
